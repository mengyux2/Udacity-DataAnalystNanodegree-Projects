{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Project - Tampa, Fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Area\n",
    "\n",
    "Tampa, FL, United States\n",
    "\n",
    "* https://www.openstreetmap.org/relation/1216849\n",
    "* https://mapzen.com/data/metro-extracts/metro/tampa_florida/\n",
    "(417.5MB)\n",
    "\n",
    "Tampa is the city I live in and familiar with, This project is to apply the techniques learned from Udacity's Data Wrangling course to parse, audit and clean this dataset then convert xml into csv, and using sql queries to explore some facts about this city.\n",
    "\n",
    "I experimented with a smaller .osm datafile named temple_terrace.osm(10.4MB), which represents my neighborhood area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Auditing and Problems Encountered\n",
    "\n",
    "* Examined element types and occurrence, this part looks fine. **(data_overview.py)**\n",
    ">Element types and occurrence of temple_terrace.osm<br />\n",
    ">[('nd', 2195579),<br />\n",
    "> ('node', 1822389),<br />\n",
    "> ('tag', 916600),<br />\n",
    "> ('way', 291596),<br />\n",
    "> ('member', 17721),<br />\n",
    "> ('relation', 670),<br />\n",
    "> ('osm', 1),<br />\n",
    "> ('bounds', 1)]<br />\n",
    "\n",
    "\n",
    "* Examined type of keys, most of them were good, 3 keys contain problem characters, which are actually blank space.\n",
    ">{'lower': 710176, 'lower_colon': 194348, 'other': 12073, 'problemchars': 3}<br />\n",
    ">service area<br />\n",
    ">Payments Accepted<br />\n",
    ">Payments Accepted<br />\n",
    "\n",
    "* Examined occurrence of keys, very few of them used deprecated notation, suffixed name tagging, such as 'cycleway_1', 'natural_1'.\n",
    "* Examined values for postcode, for the part of map I chose, postcodes are all numbers, most of them used standard five digits postcode, but a few used nine digits 'XXXXX-XXXX'. I will drop the '-XXXX' part. **(audit_clean_postcode.py)**\n",
    "* Examined values for street types, many of them are abbreiviated in different ways, such as 'Dr.', 'dr', 'Dr'for 'Drive', and 'Ave.','av','Ave'for 'Avenue'. There are also some cases of misspelling, such as 'Bolevard'. I will fix those and use standard notations.**(audit_clean_street.py)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and database import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean up postcode\n",
    "A count_postcodes() function was created to audit the postcodes in the area, and the output shows that the only issue of format inconsistency is the four digits suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postcode values and occurrence in tampa.osm\n",
      "[('33612', 167),\n",
      " ('33702', 120),\n",
      " ('33511', 109),\n",
      " ('33607', 92),\n",
      " ('33602', 89),\n",
      " ('33703', 88),\n",
      " ('33704', 79),\n",
      " ('33781', 74),\n",
      " ('33606', 71),\n",
      " ('33714', 67),\n",
      " ('33617', 67),\n",
      " ('33624', 64),\n",
      " ('33716', 59),\n",
      " ('33635', 59),\n",
      " ('33578', 57),\n",
      " ('33626', 49),\n",
      " ('34677', 45),\n",
      " ('33614', 41),\n",
      " ('33619', 37),\n",
      " ('33634', 34),\n",
      " ('33609', 32),\n",
      " ('33569', 30),\n",
      " ('33527', 27),\n",
      " ('33604', 26),\n",
      " ('33605', 24),\n",
      " ('33629', 23),\n",
      " ('33603', 22),\n",
      " ('33615', 21),\n",
      " ('33611', 21),\n",
      " ('33610', 21),\n",
      " ('33556', 20),\n",
      " ('33613', 19),\n",
      " ('33713', 18),\n",
      " ('33594', 18),\n",
      " ('33592', 18),\n",
      " ('33618', 16),\n",
      " ('33762', 14),\n",
      " ('33547', 14),\n",
      " ('33729', 13),\n",
      " ('33710', 12),\n",
      " ('33596', 8),\n",
      " ('33647', 7),\n",
      " ('33544', 7),\n",
      " ('33572', 6),\n",
      " ('33558', 6),\n",
      " ('33534', 6),\n",
      " ('34655', 5),\n",
      " ('33637', 5),\n",
      " ('33584', 5),\n",
      " ('33559', 5),\n",
      " ('34639', 4),\n",
      " ('33549', 4),\n",
      " ('33625', 3),\n",
      " ('33620', 3),\n",
      " ('33616', 3),\n",
      " ('34695', 2),\n",
      " ('34677-6300', 2),\n",
      " ('33643', 2),\n",
      " ('33579', 2),\n",
      " ('33548', 2),\n",
      " ('33510', 2),\n",
      " ('33169', 2),\n",
      " ('35655', 1),\n",
      " ('34685', 1),\n",
      " ('33761', 1),\n",
      " ('33716-1201', 1),\n",
      " ('33709', 1),\n",
      " ('33701', 1),\n",
      " ('33688', 1),\n",
      " ('33629-8171', 1),\n",
      " ('33615-3809', 1),\n",
      " ('33613-4649', 1),\n",
      " ('33613-4628', 1),\n",
      " ('33613-1612', 1),\n",
      " ('33606-2704', 1),\n",
      " ('33604-5263', 1),\n",
      " ('33543', 1),\n",
      " ('33511-8819', 1),\n",
      " ('33511-5421', 1)]\n"
     ]
    }
   ],
   "source": [
    "def count_postcodes(filename):\n",
    "    postcodes = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', 'end')):\n",
    "        if event == 'end':\n",
    "            key = elem.attrib.get('k')\n",
    "            if key == 'addr:postcode':\n",
    "                postcode = elem.attrib.get('v')\n",
    "                if postcode not in postcodes:\n",
    "                    postcodes[postcode] = 1\n",
    "                else:\n",
    "                    postcodes[postcode] += 1\n",
    "    return postcodes\n",
    "\n",
    "postcodes = count_postcodes(osm_filename)\n",
    "sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in postcodes.items()], reverse=True)]\n",
    "\n",
    "print 'Postcode values and occurrence in tampa.osm'\n",
    "pprint.pprint(sorted_by_occurrence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clean_postcode() was created to fix the inconsistency, it simply takes the first five digits of postcode_value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_postcode(postcode_value):\n",
    "\n",
    "    if len(postcode_value)!=5:\n",
    "        postcode=postcode_value[0:5]\n",
    "                        \n",
    "        return postcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standardize abbreviated street names<br />\n",
    "\n",
    "In order to standardize abbreviated street names, in audit_clean_street.py, update_name() function updates street name based on the manually created mapping dictionary.\n",
    "\n",
    ">Penrod Ln => Penrod Lane<br />\n",
    "Whitmarsh Ln => Whitmarsh Lane<br />\n",
    "Webb Rd => Webb Road<br />\n",
    "Hutchison Rd => Hutchison Road<br />\n",
    "Race Track Rd => Race Track Road<br />\n",
    "Kelly Rd => Kelly Road<br />\n",
    "Providence Rd => Providence Road<br />\n",
    "Anderson Rd => Anderson Road<br />\n",
    "Orient Rd => Orient Road<br />\n",
    "Tampa Rd => Tampa Road<br />\n",
    "Ulmerton Rd => Ulmerton Road<br />\n",
    "George Rd => George Road<br />\n",
    "Tarpon Springs Rd => Tarpon Springs Road<br />\n",
    "Ehrlich Rd => Ehrlich Road<br />\n",
    "Sheldon Rd => Sheldon Road<br />\n",
    "Palm Pointe Dr. => Palm Pointe Drive<br />\n",
    "9201 W. Waters Ave. => 9201 W. Waters Avenue<br />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping.keys():\n",
    "            name = re.sub(street_type_re, mapping[street_type], name)\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file conversion and database import\n",
    "\n",
    "* shape_element() from to_csv.py parses the elements in the OSM XML file, transforming them from document format to tabular format, thus making it possible to write to .csv files. clean_postcode() and update_name() are also plugged in so that while iterating through the osm file, the data get cleaned up.**(to_csv.py)**\n",
    "* tampa.db was created and five tables('node', 'node_tags','way','way_nodes','way_tags') were created using the designated schemas, corresponding csv data were imported to tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tampa_cleaned.xml file is 422.40293 MB\n",
      "The tampa.db file is 147.521536 MB\n",
      "The nodes.csv file is 91.539394 MB\n",
      "The nodes_tags.csv file is 91.539394 MB\n",
      "The ways.csv file is 19.066574 MB\n",
      "The ways_tags.csv is 27.487402 MB\n",
      "The ways_nodes.csv is 24.777723 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('The tampa_cleaned.xml file is {} MB'.format(os.path.getsize('tampa_cleaned.xml')/1.0e6))\n",
    "print('The tampa.db file is {} MB'.format(os.path.getsize('tampa.db')/1.0e6))\n",
    "print('The nodes.csv file is {} MB'.format(os.path.getsize('nodes.csv')/1.0e6))\n",
    "print('The nodes_tags.csv file is {} MB'.format(os.path.getsize('nodes.csv')/1.0e6))\n",
    "print('The ways.csv file is {} MB'.format(os.path.getsize('ways.csv')/1.0e6))\n",
    "print('The ways_tags.csv is {} MB'.format(os.path.getsize('ways_tags.csv')/1.0e6))\n",
    "print('The ways_nodes.csv is {} MB'.format(os.path.getsize('ways_nodes.csv')/1.0e6)) # Convert from bytes to MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1048575,)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "sqlite_file = \"tampa.db\"\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT COUNT(*) FROM nodes;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(291596,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM ways;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(893,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 contributing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Andrew Matheny_import', 404260),\n",
      " (u'ninja_import', 94536),\n",
      " (u'EdHillsman', 91743),\n",
      " (u'woodpeck_fixbot', 59404),\n",
      " (u'coleman', 58410),\n",
      " (u'David Hey', 57929),\n",
      " (u'KalininOV', 57366),\n",
      " (u'grouper', 39270),\n",
      " (u'jharpster', 37479),\n",
      " (u'Jack the Ripper', 32749)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cur.execute(\"SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 10;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tourism related categories descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'hotel', 115),\n",
      " (u'information', 57),\n",
      " (u'motel', 50),\n",
      " (u'attraction', 21),\n",
      " (u'viewpoint', 16),\n",
      " (u'museum', 15),\n",
      " (u'artwork', 12),\n",
      " (u'picnic_site', 12),\n",
      " (u'theme_park', 9),\n",
      " (u'camp_site', 6),\n",
      " (u'zoo', 4),\n",
      " (u'caravan_site', 3),\n",
      " (u'terminal', 2),\n",
      " (u'apartment', 1),\n",
      " (u'aquarium', 1),\n",
      " (u'guest_house', 1),\n",
      " (u'hostel', 1),\n",
      " (u'zoo;attraction', 1)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cur.execute (\"SELECT tags.value, COUNT(*) as count FROM (SELECT * FROM nodes_tags UNION ALL \\\n",
    "             SELECT * FROM ways_tags) tags \\\n",
    "             WHERE tags.key LIKE '%tourism'\\\n",
    "             GROUP BY tags.value \\\n",
    "             ORDER BY count DESC;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 5 cafe chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Starbucks', 15),\n",
      " (u\"Dunkin' Donuts\", 3),\n",
      " (u'Starbucks Coffee', 3),\n",
      " (u'Kaleisia Tea Lounge', 2),\n",
      " (u'Tropical Smoothie Cafe', 2)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute (\"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) \\\n",
    "             FROM nodes_tags WHERE value='cafe') i ON nodes_tags.id=i.id WHERE nodes_tags.key='name' \\\n",
    "             GROUP BY nodes_tags.value ORDER BY num DESC LIMIT 5;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 5 popular fast food chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Subway', 29),\n",
      " (u\"McDonald's\", 26),\n",
      " (u\"Wendy's\", 12),\n",
      " (u'Burger King', 11),\n",
      " (u'Chick-fil-A', 5)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute (\"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) \\\n",
    "             FROM nodes_tags WHERE value='fast_food') i ON nodes_tags.id=i.id WHERE nodes_tags.key='name' \\\n",
    "             GROUP BY nodes_tags.value ORDER BY num DESC LIMIT 5;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 5 common ammenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'restaurant', 470),\n",
      " (u'place_of_worship', 357),\n",
      " (u'bicycle_parking', 263),\n",
      " (u'school', 233),\n",
      " (u'fast_food', 227),\n",
      " (u'fuel', 147),\n",
      " (u'fountain', 101),\n",
      " (u'bench', 99),\n",
      " (u'bank', 83),\n",
      " (u'cafe', 54)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute (\"SELECT value, COUNT(*) as num \\\n",
    "FROM nodes_tags \\\n",
    "WHERE key='amenity'\\\n",
    "GROUP BY value \\\n",
    "ORDER BY num DESC \\\n",
    "LIMIT 10;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 5 religions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'christian', 335),\n",
      " (u'buddhist', 2),\n",
      " (u'jewish', 2),\n",
      " (u'scientologist', 2),\n",
      " (u'bahai', 1)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT nodes_tags.value, COUNT(*) as num \\\n",
    "FROM nodes_tags \\\n",
    "    JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='place_of_worship') i \\\n",
    "    ON nodes_tags.id=i.id \\\n",
    "WHERE nodes_tags.key='religion' \\\n",
    "GROUP BY nodes_tags.value \\\n",
    "ORDER BY num DESC \\\n",
    "LIMIT 5;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and further improvement suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ideas about the datasets\n",
    "\n",
    "OpenStreetMap for city of tampa has reasonable quality, it provides limited but quite reliable information, as we saw some expected results in data exploration section. I have used basic data auditing and data cleaning techniques to programatically fixed large amount of data, significant problems are still exists:\n",
    "* lack of user participation and timely update. To this point, gamification can be implemented to encourage user participation through incentives, perhaps binding the map with some feature like pokemon go would help.\n",
    "* Automated data auditing may be implemented through some Cross-referencing/Cross-validating by plugging in Google API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "173 users input data only once. above mentioned gamification has the potential to engage more users and encourage participation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(173,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM \\\n",
    "    (SELECT e.user, COUNT(*) as num \\\n",
    "     FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e \\\n",
    "     GROUP BY e.user \\\n",
    "     HAVING num=1)  u;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits and Anticipated Problems in Implementing the Improvement\n",
    "\n",
    "* Benefits: More data input, more potential to extend OpenStreetMap. This open source allows people to include travel, walking and biking tour information, user reviews of establishments, local public transit etc. This could expand OpenStreetMap's user base, and become more consumer focused. Also, increased utility of this map will attract more local businesses to take care of data quality related to them.\n",
    "* Anticipated Problems: OpenStreeMap has no paid employees, the growth and expansion only based on volunteer users, additionaly, there is learning curve to figure out what OpenStreeMap is about(myself as an example), therefore it's hard to attract users especially some easy-to-use map apps like Google map are so dominant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------end of report-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### working code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element types and occurrence of tampa.osm\n",
      "[('nd', 2195579),\n",
      " ('node', 1822389),\n",
      " ('tag', 916600),\n",
      " ('way', 291596),\n",
      " ('member', 17721),\n",
      " ('relation', 670),\n",
      " ('osm', 1),\n",
      " ('bounds', 1)]\n"
     ]
    }
   ],
   "source": [
    "osm_sample = 'temple_terrace.osm'\n",
    "osm_filename = 'tampa.osm'\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', )):\n",
    "        if elem.tag not in tags:\n",
    "            tags[elem.tag] = 1\n",
    "        else:\n",
    "            tags[elem.tag] += 1\n",
    "    return tags\n",
    "\n",
    "tags = count_tags(osm_filename)\n",
    "sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in tags.items()], reverse=True)]\n",
    "\n",
    "print 'Element types and occurrence of tampa.osm'\n",
    "pprint.pprint(sorted_by_occurrence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key types and occurrence of tampa.osm\n",
      "problemchars: service area\n",
      "problemchars: Payments Accepted\n",
      "problemchars: Payments Accepted\n",
      "{'lower': 710176, 'lower_colon': 194348, 'other': 12073, 'problemchars': 3}\n"
     ]
    }
   ],
   "source": [
    "##regular expressions to define tag key characters\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        for tag in element.iter('tag'):\n",
    "            k = tag.get('k')\n",
    "            if lower.search(element.attrib['k']):\n",
    "                keys['lower'] = keys['lower'] + 1\n",
    "            elif lower_colon.search(element.attrib['k']):\n",
    "                keys['lower_colon'] = keys['lower_colon'] + 1\n",
    "            elif problemchars.search(element.attrib['k']):\n",
    "                print 'problemchars:',k\n",
    "                keys['problemchars'] = keys['problemchars'] + 1\n",
    "            else:\n",
    "                #print k\n",
    "                keys['other'] = keys['other'] + 1\n",
    "    \n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "print 'Key types and occurrence of tampa.osm'\n",
    "pprint.pprint(process_map(osm_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys and occurrence in tampa.osm\n",
      "[('building', 225093),\n",
      " ('height', 216193),\n",
      " ('highway', 62865),\n",
      " ('name', 38998),\n",
      " ('tiger:county', 23293),\n",
      " ('tiger:cfcc', 23257),\n",
      " ('tiger:name_base', 21924),\n",
      " ('tiger:name_type', 21637),\n",
      " ('tiger:reviewed', 20105),\n",
      " ('tiger:zip_left', 18477),\n",
      " ('tiger:zip_right', 17650),\n",
      " ('source', 12530),\n",
      " ('oneway', 11169),\n",
      " ('power', 9668),\n",
      " ('surface', 7776),\n",
      " ('lanes', 7449),\n",
      " ('maxspeed', 6108),\n",
      " ('natural', 5882),\n",
      " ('service', 5632),\n",
      " ('amenity', 5630)]\n"
     ]
    }
   ],
   "source": [
    "def count_keys(filename):\n",
    "    keys = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', 'end')):\n",
    "        if event == 'end':\n",
    "            key = elem.attrib.get('k')\n",
    "            if key:\n",
    "                if key not in keys:\n",
    "                    keys[key] = 1\n",
    "                else:\n",
    "                    keys[key] += 1\n",
    "    return keys\n",
    "\n",
    "keys = count_keys(osm_filename)\n",
    "sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in keys.items()], reverse=True)]\n",
    "\n",
    "print 'Keys and occurrence in tampa.osm'\n",
    "pprint.pprint(sorted_by_occurrence[0:20]) ##print 20 most frequent keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postcode values and occurrence in tampa.osm\n",
      "[('33612', 167),\n",
      " ('33702', 120),\n",
      " ('33511', 109),\n",
      " ('33607', 92),\n",
      " ('33602', 89),\n",
      " ('33703', 88),\n",
      " ('33704', 79),\n",
      " ('33781', 74),\n",
      " ('33606', 71),\n",
      " ('33714', 67),\n",
      " ('33617', 67),\n",
      " ('33624', 64),\n",
      " ('33716', 59),\n",
      " ('33635', 59),\n",
      " ('33578', 57),\n",
      " ('33626', 49),\n",
      " ('34677', 45),\n",
      " ('33614', 41),\n",
      " ('33619', 37),\n",
      " ('33634', 34),\n",
      " ('33609', 32),\n",
      " ('33569', 30),\n",
      " ('33527', 27),\n",
      " ('33604', 26),\n",
      " ('33605', 24),\n",
      " ('33629', 23),\n",
      " ('33603', 22),\n",
      " ('33615', 21),\n",
      " ('33611', 21),\n",
      " ('33610', 21),\n",
      " ('33556', 20),\n",
      " ('33613', 19),\n",
      " ('33713', 18),\n",
      " ('33594', 18),\n",
      " ('33592', 18),\n",
      " ('33618', 16),\n",
      " ('33762', 14),\n",
      " ('33547', 14),\n",
      " ('33729', 13),\n",
      " ('33710', 12),\n",
      " ('33596', 8),\n",
      " ('33647', 7),\n",
      " ('33544', 7),\n",
      " ('33572', 6),\n",
      " ('33558', 6),\n",
      " ('33534', 6),\n",
      " ('34655', 5),\n",
      " ('33637', 5),\n",
      " ('33584', 5),\n",
      " ('33559', 5),\n",
      " ('34639', 4),\n",
      " ('33549', 4),\n",
      " ('33625', 3),\n",
      " ('33620', 3),\n",
      " ('33616', 3),\n",
      " ('34695', 2),\n",
      " ('34677-6300', 2),\n",
      " ('33643', 2),\n",
      " ('33579', 2),\n",
      " ('33548', 2),\n",
      " ('33510', 2),\n",
      " ('33169', 2),\n",
      " ('35655', 1),\n",
      " ('34685', 1),\n",
      " ('33761', 1),\n",
      " ('33716-1201', 1),\n",
      " ('33709', 1),\n",
      " ('33701', 1),\n",
      " ('33688', 1),\n",
      " ('33629-8171', 1),\n",
      " ('33615-3809', 1),\n",
      " ('33613-4649', 1),\n",
      " ('33613-4628', 1),\n",
      " ('33613-1612', 1),\n",
      " ('33606-2704', 1),\n",
      " ('33604-5263', 1),\n",
      " ('33543', 1),\n",
      " ('33511-8819', 1),\n",
      " ('33511-5421', 1)]\n"
     ]
    }
   ],
   "source": [
    "def count_postcodes(filename):\n",
    "    postcodes = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', 'end')):\n",
    "        if event == 'end':\n",
    "            key = elem.attrib.get('k')\n",
    "            if key == 'addr:postcode':\n",
    "                postcode = elem.attrib.get('v')\n",
    "                if postcode not in postcodes:\n",
    "                    postcodes[postcode] = 1\n",
    "                else:\n",
    "                    postcodes[postcode] += 1\n",
    "    return postcodes\n",
    "\n",
    "\n",
    "#start_time = time.time()\n",
    "\n",
    "postcodes = count_postcodes(osm_filename)\n",
    "sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in postcodes.items()], reverse=True)]\n",
    "\n",
    "print 'Postcode values and occurrence in tampa.osm'\n",
    "pprint.pprint(sorted_by_occurrence)\n",
    "\n",
    "#print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_postcode(postcode_value):\n",
    "\n",
    "    if len(postcode_value)!=5:\n",
    "        postcode=postcode_value[0:5]\n",
    "                        \n",
    "        return postcode\n",
    "    #return tree.write(cleaned_filename)\n",
    "\n",
    "\n",
    "#start_time = time.time()\n",
    "\n",
    "#cleaned_postcode = 'tampa_cleaned_postcode.xml'\n",
    "#clean_postcode(osm_filename, cleaned_postcode)\n",
    "\n",
    "\n",
    "#print('\\n--- %s seconds ---' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#postcodes = count_postcodes('tampa_cleaned_postcode.xml')\n",
    "#sorted_by_occurrence = [(k, v) for (v, k) in sorted([(value, key) for (key, value) in postcodes.items()], reverse=True)]\n",
    "\n",
    "#print 'Postcode values and occurrence after cleaning:\\n'\n",
    "#pprint.pprint(sorted_by_occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'1002': {'N. Westshore BLVD #1002'},\n",
       "             '101': {'Ulmerton Rd, Suite 101'},\n",
       "             '102': {'FL-54 #102'},\n",
       "             '103': {'Ulmerton Rd, Suite 103'},\n",
       "             '105': {'S Howard Av 105'},\n",
       "             '106': {'Ulmerton Rd, Suite 106'},\n",
       "             '107': {'Ulmerton Rd, Suite 107'},\n",
       "             '131': {'E Fletcher Ave #131'},\n",
       "             '19': {'US 19'},\n",
       "             '201': {'Ulmerton Rd, Suite 201'},\n",
       "             '202': {'Ulmerton Rd, Suite 202'},\n",
       "             '203': {'Ulmerton Rd, Suite 203'},\n",
       "             '206': {'Ulmerton Rd, Suite 206'},\n",
       "             '250': {'North Armenia Avenue Suite #250'},\n",
       "             '300': {'W Palmira Ave #300'},\n",
       "             '301': {'S US Highway 301',\n",
       "              'South US Highway 301',\n",
       "              'US 301',\n",
       "              'US Highway 301',\n",
       "              'us Highway 301'},\n",
       "             '33635': {'8492 Manatee Bay Dr Tampa, FL 33635'},\n",
       "             '41': {'N US Highway 41'},\n",
       "             '54': {'FL 54', 'SR 54'},\n",
       "             '56': {'SR 56'},\n",
       "             '60': {'FL 60'},\n",
       "             '60)': {'West Brandon Blvd (S.R. 60)'},\n",
       "             '92': {'12000 US Highway 92', 'US 92'},\n",
       "             'Av': {'Fletcher Av'},\n",
       "             'Ave': {'12th Ave',\n",
       "              '64th Ave',\n",
       "              'E 21st Ave',\n",
       "              'E 27th Ave',\n",
       "              'E 7th Ave',\n",
       "              'E 8th Ave',\n",
       "              'E Fletcher Ave',\n",
       "              'E Floribraska Ave',\n",
       "              'E Fowler Ave',\n",
       "              'E Palm Ave',\n",
       "              'East Fletcher Ave',\n",
       "              'East Fowler Ave',\n",
       "              'Fletcher Ave',\n",
       "              'Hillsborough Ave',\n",
       "              'Livingston Ave',\n",
       "              'N Armenia Ave',\n",
       "              'N Central Ave',\n",
       "              'N Florida Ave',\n",
       "              'N Highland Ave',\n",
       "              'N Nebraska Ave',\n",
       "              'N Rome Ave',\n",
       "              'N Suwanee Ave',\n",
       "              'N Willow Ave',\n",
       "              'S Florida Ave',\n",
       "              'S Howard Ave',\n",
       "              'S Hyde Park Ave',\n",
       "              'S Manhattan Ave',\n",
       "              'S Martindale Ave',\n",
       "              'S Orleans Ave',\n",
       "              'W Grand Central Ave',\n",
       "              'W Jetton Ave',\n",
       "              'W Mango Ave',\n",
       "              'W Paxton Ave',\n",
       "              'W Pearl Ave',\n",
       "              'W Snow Ave',\n",
       "              'W Swann Ave',\n",
       "              'W Waters Ave',\n",
       "              'W.Hillsborough Ave',\n",
       "              'West Hillsborough Ave'},\n",
       "             'Ave.': {'9201 W. Waters Ave.', 'E. Fowler Ave.'},\n",
       "             'B': {'N Florida Ave #B'},\n",
       "             'Blvd': {'Bayshore Blvd',\n",
       "              'Beaumont Center Blvd',\n",
       "              'Bruce B Downs Blvd',\n",
       "              'Cross Creek Blvd',\n",
       "              'Cypress Ridge Blvd',\n",
       "              'E Kennedy Blvd',\n",
       "              'E.Kennedy Blvd',\n",
       "              'East Kennedy Blvd',\n",
       "              'Egret Blvd',\n",
       "              'Forest Lakes Blvd',\n",
       "              'Gandy Blvd',\n",
       "              'Henderson Blvd',\n",
       "              'Interbay Blvd',\n",
       "              'Land O Lakes Blvd',\n",
       "              'N Westshore Blvd',\n",
       "              'North Blvd',\n",
       "              'Paradise Lakes Blvd',\n",
       "              'Park Blvd',\n",
       "              'Town Center Blvd',\n",
       "              'W Gandy Blvd',\n",
       "              'W Kennedy Blvd',\n",
       "              'West Kennedy Blvd'},\n",
       "             'Blvd.': {'10314 Wilsky Blvd.',\n",
       "              'E Kennedy Blvd.',\n",
       "              'East Kennedy Blvd.',\n",
       "              'Grand Regency Blvd.',\n",
       "              'Tampa Gateway Blvd.',\n",
       "              'W Brandon Blvd.'},\n",
       "             'Bolevard': {'North Westshore Bolevard'},\n",
       "             'Boulvard': {'East Kennedy Boulvard'},\n",
       "             'C': {'S. MacDill Ave, Suite C'},\n",
       "             'C4': {'Tampa Road #C4'},\n",
       "             'Cir': {'Bay Club Cir', 'DuPont Cir', 'Dupont Cir'},\n",
       "             'Circle': {'Crescent Loop Circle',\n",
       "              'Primrose Lake Circle',\n",
       "              'Reuter Strasse Circle',\n",
       "              'Ridgebrook Circle',\n",
       "              'South Village Circle',\n",
       "              'Thomasville Circle',\n",
       "              'Thomsville Circle',\n",
       "              'USF Cedar Circle',\n",
       "              'Vieux Carre Circle',\n",
       "              'Vista Del Sol Circle'},\n",
       "             'Cswy': {'Courtney Campbell Cswy', 'W Courtney Campbell Cswy'},\n",
       "             'Ct': {'Carrollwood Ct', 'Edgewater Ct'},\n",
       "             'Cuba': {'Avenue Republica de Cuba',\n",
       "              'North Avenue Republica de Cuba'},\n",
       "             'Dr': {'1228 Charlesworth Dr',\n",
       "              'Canopy Dr',\n",
       "              'Channelside Dr',\n",
       "              'Citrus Park Dr',\n",
       "              'Citrus Village Dr',\n",
       "              'Cypress Ridge Dr',\n",
       "              'E Adamo Dr',\n",
       "              'Elliott Dr',\n",
       "              'Garden Vista Dr',\n",
       "              'Gennaker Dr',\n",
       "              'Harbour Post Dr',\n",
       "              'Health Care Dr',\n",
       "              'Lake Carillon Dr',\n",
       "              'N Ashley Dr',\n",
       "              'N McKinley Dr',\n",
       "              'Reflections Club Dr',\n",
       "              'Ridge Point Dr',\n",
       "              'Rocky Creek Dr',\n",
       "              'South Riverhills Dr',\n",
       "              'St Petersburg Dr',\n",
       "              'University Dr',\n",
       "              'W Columbus Dr',\n",
       "              'Winter Crest Dr'},\n",
       "             'Dr.': {'Palm Pointe Dr.'},\n",
       "             'E': {'Enterprise Rd E',\n",
       "              'N Rocky Point Dr E',\n",
       "              'State Rd 60 E',\n",
       "              'State Road 54 #E',\n",
       "              'State St E'},\n",
       "             'East': {'North Rocky Point Drive East',\n",
       "              'Pine Ridge Circle East',\n",
       "              'Shore Drive East',\n",
       "              'State Road 60 East'},\n",
       "             'FL)': {'US 301 (FL)'},\n",
       "             'Highway': {'Dale Mabry Highway',\n",
       "              'Gunn Highway',\n",
       "              'Memorial Highway',\n",
       "              'N Dale Mabry Highway',\n",
       "              'North Dale Mabry Highway',\n",
       "              'South Dale Mabry Highway'},\n",
       "             'Hwy': {'N. Dale Mabry Hwy'},\n",
       "             'Ln': {'Penrod Ln', 'Whitmarsh Ln'},\n",
       "             'Loop': {'Simmons Loop'},\n",
       "             'Mall': {'University Square Mall'},\n",
       "             'N': {'110th Ave N',\n",
       "              '12th Ave N',\n",
       "              '12th St N',\n",
       "              '13th Ave N',\n",
       "              '16th Street N',\n",
       "              '1st St N',\n",
       "              '1st Street N',\n",
       "              '22nd Avenue N',\n",
       "              '25th St N',\n",
       "              '27th Ave N',\n",
       "              '28th Street N',\n",
       "              '29th St N',\n",
       "              '31st St N',\n",
       "              '33rd Ave N',\n",
       "              '34th St N',\n",
       "              '34th Street N',\n",
       "              '37th Ave N',\n",
       "              '37th Avenue N',\n",
       "              '38th Ave N',\n",
       "              '44th Ave N',\n",
       "              '47th Ave N',\n",
       "              '4th St N',\n",
       "              '4th Street N',\n",
       "              '51st Ave N',\n",
       "              '52nd Avenue N',\n",
       "              '54th Avenue N',\n",
       "              '5th Street N',\n",
       "              '61st Ave N',\n",
       "              '62nd Ave N',\n",
       "              '74th Ave N',\n",
       "              '77th Ave N',\n",
       "              '87th Ave N',\n",
       "              '90th Ave N',\n",
       "              '9th St N',\n",
       "              '9th Street N',\n",
       "              'Dr Ml King Jr St N',\n",
       "              'Haines Rd N',\n",
       "              'Haines Road N',\n",
       "              'Kingsboro Dr N',\n",
       "              'Northwest Blvd N',\n",
       "              'Pine Ave N',\n",
       "              'Roosevelt Blvd N',\n",
       "              'SW Jefferson Cir N',\n",
       "              'US 19 N',\n",
       "              'US Highway 19 N',\n",
       "              'US Hwy 19 N',\n",
       "              'Valpak Ave N'},\n",
       "             'NE': {'38th Avenue NE',\n",
       "              'Brighton Bay Blvd NE',\n",
       "              'San Martin Blvd NE',\n",
       "              'Snell Isle Boulevard NE'},\n",
       "             'North': {'106th Avenue North',\n",
       "              '109th Avenue North',\n",
       "              '118th Avenue North',\n",
       "              '12th Avenue North',\n",
       "              '14th Street North',\n",
       "              '16th Street North',\n",
       "              '1st Street North',\n",
       "              '22nd Avenue North',\n",
       "              '25th Street North',\n",
       "              '28th Street North',\n",
       "              '30th Avenue North',\n",
       "              '30th Court North',\n",
       "              '34th Street North',\n",
       "              '35th Street North',\n",
       "              '37th Avenue North',\n",
       "              '3rd Street North',\n",
       "              '48th Avenue North',\n",
       "              '4th Street North',\n",
       "              '50th Avenue North',\n",
       "              '53rd Avenue North',\n",
       "              '54th Avenue North',\n",
       "              '5th Street North',\n",
       "              '62nd Ave North',\n",
       "              '62nd Avenue North',\n",
       "              '70th Avenue North',\n",
       "              '72nd Avenue North',\n",
       "              '94th Avenue North',\n",
       "              '9th Street North',\n",
       "              'Doctor Martin Luther King Junior Street North',\n",
       "              'Haines Road North',\n",
       "              'Pine Avenue North',\n",
       "              'Roosevelt Boulevard North',\n",
       "              'Tampa Street North',\n",
       "              'US 301 North',\n",
       "              'US Highway 19 North'},\n",
       "             'Northeast': {'15th Avenue Northeast',\n",
       "              '1st Street Northeast',\n",
       "              '37th Ave Northeast',\n",
       "              '62nd Ave Northeast',\n",
       "              '89th Avenue Northeast',\n",
       "              'Addison Drive Northeast',\n",
       "              'Arrowhead Drive Northeast',\n",
       "              'Foch Street Northeast',\n",
       "              'Lee Street Northeast',\n",
       "              'Shore Acres Boulevard Northeast',\n",
       "              'Tennessee Avenue Northeast'},\n",
       "             'Notth': {'4th Street Notth'},\n",
       "             'Pkwy': {'Bullard Pkwy', 'Carillon Pkwy'},\n",
       "             'Pky': {'Independence Pky'},\n",
       "             'Pl': {'17501 N Palms Village Pl', 'Harvest Pl', 'University Pl'},\n",
       "             'Plaza': {'Fiesta Plaza',\n",
       "              'International Plaza',\n",
       "              'University Plaza'},\n",
       "             'Prkg': {'W Swann Av Prkg'},\n",
       "             'Rd': {'Anderson Rd',\n",
       "              'Ehrlich Rd',\n",
       "              'George Rd',\n",
       "              'Hutchison Rd',\n",
       "              'Kelly Rd',\n",
       "              'Orient Rd',\n",
       "              'Providence Rd',\n",
       "              'Race Track Rd',\n",
       "              'Sheldon Rd',\n",
       "              'Tampa Rd',\n",
       "              'Tarpon Springs Rd',\n",
       "              'Ulmerton Rd',\n",
       "              'Webb Rd'},\n",
       "             'Rd.': {'8203 Peterson Rd.', 'W Lumsden Rd.'},\n",
       "             'S': {'Eisenhower Blvd S', 'US Highway 301 S'},\n",
       "             'South': {'Eisenhower Boulevard South',\n",
       "              'U.S. Highway 301 South',\n",
       "              'US Highway 301 South'},\n",
       "             'Southeast': {'Jefferson Circle Southeast'},\n",
       "             'St': {'34th St',\n",
       "              '4th St',\n",
       "              '7499 Montague St',\n",
       "              'Clarendon St',\n",
       "              'E Cass St',\n",
       "              'E Madison St',\n",
       "              'E Rampart St',\n",
       "              'E Twiggs St',\n",
       "              'E Tyler St',\n",
       "              'E Zack St',\n",
       "              'Montague St',\n",
       "              'N 19th St',\n",
       "              'N 22nd St',\n",
       "              'N 25th St',\n",
       "              'N 50th St',\n",
       "              'N Franklin St',\n",
       "              'N Marion St',\n",
       "              'N Morgan St',\n",
       "              'N Pierce St',\n",
       "              'N Tampa St',\n",
       "              'Ninth St',\n",
       "              'Old Water St',\n",
       "              'S Franklin St',\n",
       "              'S Occident St',\n",
       "              'S Parker St',\n",
       "              'South 22nd St',\n",
       "              'South Trask St',\n",
       "              'W Azeele St',\n",
       "              'W Cass St',\n",
       "              'W Corona St',\n",
       "              'W Fortune St',\n",
       "              'W Gladys St',\n",
       "              'W Horatio St',\n",
       "              'W North B St',\n",
       "              'W Platt St'},\n",
       "             'Suite#101': {'W Cypress St Suite#101'},\n",
       "             'US-19': {'US-19'},\n",
       "             'US-301': {'US-301'},\n",
       "             'W': {'Dr MLK Jr Blvd W'},\n",
       "             'Way': {'Azalea Bloom Way',\n",
       "              'Carriage Way',\n",
       "              'Channelside Walk Way',\n",
       "              'Magenta Way',\n",
       "              'Satinwood Way'},\n",
       "             'West': {'Shore Drive West', 'Tampa Palms Boulevard West'},\n",
       "             'dr': {'benjamin center dr'},\n",
       "             'drive': {'Markstown drive'},\n",
       "             'road': {'Racetrack road'}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"av\":\"Avenue\",\n",
    "            \"ave\": \"Avenue\",\n",
    "           'Ave.':\"Avenue\",\n",
    "           'Blvd':\"Boulevard\",\n",
    "           'Blvd.':\"Boulevard\",\n",
    "           'Bolevard':\"Boulevard\",\n",
    "           'Boulvard':\"Boulevard\",\n",
    "           'Cir':\"Circle\",\n",
    "           'Cswy':\"Causeway\",\n",
    "           'Ct':\"Court\",\n",
    "           'Dr':\"Drive\",\n",
    "           'Dr.':\"Drive\",\n",
    "           'Hwy':\"Highway\",\n",
    "           'Ln':\"Lane\",\n",
    "           'Pkwy':\"Parkway\",\n",
    "           'Pky':\"Parking\",\n",
    "           'Pl':\"Plaza\",\n",
    "           'Rd':\"Road\",\n",
    "           'Rd.':\"Road\",\n",
    "           'St':\"Street\",\n",
    "           'street':\"Street\",\n",
    "           'dr':\"Drive\",\n",
    "           'drive':\"Drive\"          \n",
    "}\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if tag.attrib['k'] == \"addr:street\":\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    return street_types\n",
    "\n",
    "audit(osm_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penrod Ln => Penrod Lane\n",
      "Whitmarsh Ln => Whitmarsh Lane\n",
      "Webb Rd => Webb Road\n",
      "Hutchison Rd => Hutchison Road\n",
      "Race Track Rd => Race Track Road\n",
      "Kelly Rd => Kelly Road\n",
      "Providence Rd => Providence Road\n",
      "Anderson Rd => Anderson Road\n",
      "Orient Rd => Orient Road\n",
      "Tampa Rd => Tampa Road\n",
      "Ulmerton Rd => Ulmerton Road\n",
      "George Rd => George Road\n",
      "Tarpon Springs Rd => Tarpon Springs Road\n",
      "Ehrlich Rd => Ehrlich Road\n",
      "Sheldon Rd => Sheldon Road\n",
      "Palm Pointe Dr. => Palm Pointe Drive\n",
      "9201 W. Waters Ave. => 9201 W. Waters Avenue\n",
      "E. Fowler Ave. => E. Fowler Avenue\n",
      "8203 Peterson Rd. => 8203 Peterson Road\n",
      "W Lumsden Rd. => W Lumsden Road\n",
      "University Pl => University Plaza\n",
      "17501 N Palms Village Pl => 17501 N Palms Village Plaza\n",
      "Harvest Pl => Harvest Plaza\n",
      "benjamin center dr => benjamin center Drive\n",
      "Markstown drive => Markstown Drive\n",
      "N. Dale Mabry Hwy => N. Dale Mabry Highway\n",
      "Bullard Pkwy => Bullard Parkway\n",
      "Carillon Pkwy => Carillon Parkway\n",
      "Harbour Post Dr => Harbour Post Drive\n",
      "Citrus Park Dr => Citrus Park Drive\n",
      "Rocky Creek Dr => Rocky Creek Drive\n",
      "Lake Carillon Dr => Lake Carillon Drive\n",
      "Citrus Village Dr => Citrus Village Drive\n",
      "Canopy Dr => Canopy Drive\n",
      "Garden Vista Dr => Garden Vista Drive\n",
      "W Columbus Dr => W Columbus Drive\n",
      "Winter Crest Dr => Winter Crest Drive\n",
      "N McKinley Dr => N McKinley Drive\n",
      "St Petersburg Dr => St Petersburg Drive\n",
      "University Dr => University Drive\n",
      "Cypress Ridge Dr => Cypress Ridge Drive\n",
      "South Riverhills Dr => South Riverhills Drive\n",
      "Elliott Dr => Elliott Drive\n",
      "Ridge Point Dr => Ridge Point Drive\n",
      "Channelside Dr => Channelside Drive\n",
      "E Adamo Dr => E Adamo Drive\n",
      "1228 Charlesworth Dr => 1228 Charlesworth Drive\n",
      "Health Care Dr => Health Care Drive\n",
      "Gennaker Dr => Gennaker Drive\n",
      "N Ashley Dr => N Ashley Drive\n",
      "Reflections Club Dr => Reflections Club Drive\n",
      "North Westshore Bolevard => North Westshore Boulevard\n",
      "Dupont Cir => Dupont Circle\n",
      "DuPont Cir => DuPont Circle\n",
      "Bay Club Cir => Bay Club Circle\n",
      "East Kennedy Boulvard => East Kennedy Boulevard\n",
      "N Franklin St => N Franklin Street\n",
      "S Parker St => S Parker Street\n",
      "34th St => 34th Street\n",
      "N Pierce St => N Pierce Street\n",
      "Clarendon St => Clarendon Street\n",
      "S Franklin St => S Franklin Street\n",
      "N 50th St => N 50th Street\n",
      "E Madison St => E Madison Street\n",
      "W Fortune St => W Fortune Street\n",
      "N Marion St => N Marion Street\n",
      "E Rampart St => E Rampart Street\n",
      "W Horatio St => W Horatio Street\n",
      "7499 Montague St => 7499 Montague Street\n",
      "E Zack St => E Zack Street\n",
      "South Trask St => South Trask Street\n",
      "W Gladys St => W Gladys Street\n",
      "N Morgan St => N Morgan Street\n",
      "S Occident St => S Occident Street\n",
      "South 22nd St => South 22nd Street\n",
      "Old Water St => Old Water Street\n",
      "N 19th St => N 19th Street\n",
      "W North B St => W North B Street\n",
      "4th St => 4th Street\n",
      "Montague St => Montague Street\n",
      "N 25th St => N 25th Street\n",
      "E Twiggs St => E Twiggs Street\n",
      "N 22nd St => N 22nd Street\n",
      "E Cass St => E Cass Street\n",
      "W Azeele St => W Azeele Street\n",
      "W Platt St => W Platt Street\n",
      "W Corona St => W Corona Street\n",
      "N Tampa St => N Tampa Street\n",
      "E Tyler St => E Tyler Street\n",
      "W Cass St => W Cass Street\n",
      "Ninth St => Ninth Street\n",
      "10314 Wilsky Blvd. => 10314 Wilsky Boulevard\n",
      "Tampa Gateway Blvd. => Tampa Gateway Boulevard\n",
      "East Kennedy Blvd. => East Kennedy Boulevard\n",
      "W Brandon Blvd. => W Brandon Boulevard\n",
      "E Kennedy Blvd. => E Kennedy Boulevard\n",
      "Grand Regency Blvd. => Grand Regency Boulevard\n",
      "Independence Pky => Independence Parking\n",
      "W Courtney Campbell Cswy => W Courtney Campbell Causeway\n",
      "Courtney Campbell Cswy => Courtney Campbell Causeway\n",
      "Land O Lakes Blvd => Land O Lakes Boulevard\n",
      "East Kennedy Blvd => East Kennedy Boulevard\n",
      "E Kennedy Blvd => E Kennedy Boulevard\n",
      "North Blvd => North Boulevard\n",
      "Cross Creek Blvd => Cross Creek Boulevard\n",
      "Paradise Lakes Blvd => Paradise Lakes Boulevard\n",
      "N Westshore Blvd => N Westshore Boulevard\n",
      "E.Kennedy Blvd => E.Kennedy Boulevard\n",
      "Henderson Blvd => Henderson Boulevard\n",
      "W Gandy Blvd => W Gandy Boulevard\n",
      "West Kennedy Blvd => West Kennedy Boulevard\n",
      "W Kennedy Blvd => W Kennedy Boulevard\n",
      "Beaumont Center Blvd => Beaumont Center Boulevard\n",
      "Bayshore Blvd => Bayshore Boulevard\n",
      "Park Blvd => Park Boulevard\n",
      "Cypress Ridge Blvd => Cypress Ridge Boulevard\n",
      "Interbay Blvd => Interbay Boulevard\n",
      "Bruce B Downs Blvd => Bruce B Downs Boulevard\n",
      "Forest Lakes Blvd => Forest Lakes Boulevard\n",
      "Egret Blvd => Egret Boulevard\n",
      "Gandy Blvd => Gandy Boulevard\n",
      "Town Center Blvd => Town Center Boulevard\n",
      "Edgewater Ct => Edgewater Court\n",
      "Carrollwood Ct => Carrollwood Court\n"
     ]
    }
   ],
   "source": [
    "def update_name(name, mapping):\n",
    "\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping.keys():\n",
    "            name = re.sub(street_type_re, mapping[street_type], name)\n",
    "\n",
    "    return name\n",
    "\n",
    "street_types = audit(osm_filename)\n",
    "\n",
    "for st_type, ways in street_types.iteritems():\n",
    "    for name in ways:\n",
    "        better_name = update_name(name, mapping)\n",
    "        if name != better_name:\n",
    "            print name, \"=>\", better_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def clean_street_name(filename):\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for tag in root.findall('*/tag'):\n",
    "        if is_street_name(tag):\n",
    "            name = tag.get('v')\n",
    "            better_name = update_name(name, mapping)\n",
    "            tag.set('v', better_name)\n",
    "\n",
    "    #return tree.write(cleaned_filename)\n",
    "\n",
    "#cleaned_street_name = 'tampa_cleaned.xml'\n",
    "#clean_street_name(cleaned_postcode, cleaned_street_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load 'schema.py'\n",
    "\n",
    "# Note: The schema is stored in a .py file in order to take advantage of the\n",
    "# int() and float() type coercion functions. Otherwise it could easily stored as\n",
    "# as JSON or another serialized format.\n",
    "\n",
    "schema = {\n",
    "    'node': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'dict',\n",
    "        'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\"\"\"\n",
    "After auditing is complete the next step is to prepare the data to be inserted into a SQL database.\n",
    "To do so you will parse the elements in the OSM XML file, transforming them from document format to\n",
    "tabular format, thus making it possible to write to .csv files.  These csv files can then easily be\n",
    "imported to a SQL database as tables.\n",
    "\n",
    "The process for this transformation is as follows:\n",
    "- Use iterparse to iteratively step through each top level element in the XML\n",
    "- Shape each element into several data structures using a custom function\n",
    "- Utilize a schema and validation library to ensure the transformed data is in the correct format\n",
    "- Write each data structure to the appropriate .csv files\n",
    "\n",
    "We've already provided the code needed to load the data, perform iterative parsing and write the\n",
    "output to csv files. Your task is to complete the shape_element function that will transform each\n",
    "element into the correct format. To make this process easier we've already defined a schema (see\n",
    "the schema.py file in the last code tab) for the .csv files and the eventual tables. Using the \n",
    "cerberus library we can validate the output against this schema to ensure it is correct.\n",
    "\n",
    "## Shape Element Function\n",
    "The function should take as input an iterparse Element object and return a dictionary.\n",
    "\n",
    "### If the element top level tag is \"node\":\n",
    "The dictionary returned should have the format {\"node\": .., \"node_tags\": ...}\n",
    "\n",
    "The \"node\" field should hold a dictionary of the following top level node attributes:\n",
    "- id\n",
    "- user\n",
    "- uid\n",
    "- version\n",
    "- lat\n",
    "- lon\n",
    "- timestamp\n",
    "- changeset\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"node_tags\" field should hold a list of dictionaries, one per secondary tag. Secondary tags are\n",
    "child tags of node which have the tag name/type: \"tag\". Each dictionary should have the following\n",
    "fields from the secondary tag attributes:\n",
    "- id: the top level node id attribute value\n",
    "- key: the full tag \"k\" attribute value if no colon is present or the characters after the colon if one is.\n",
    "- value: the tag \"v\" attribute value\n",
    "- type: either the characters before the colon in the tag \"k\" value or \"regular\" if a colon\n",
    "        is not present.\n",
    "\n",
    "Additionally,\n",
    "\n",
    "- if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "- if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type\n",
    "  and characters after the \":\" should be set as the tag key\n",
    "- if there are additional \":\" in the \"k\" value they and they should be ignored and kept as part of\n",
    "  the tag key. For example:\n",
    "\n",
    "  <tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "  should be turned into\n",
    "  {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "\n",
    "- If a node has no secondary tags then the \"node_tags\" field should just contain an empty list.\n",
    "\n",
    "The final return value for a \"node\" element should look something like:\n",
    "\n",
    "{'node': {'id': 757860928,\n",
    "          'user': 'uboot',\n",
    "          'uid': 26299,\n",
    "       'version': '2',\n",
    "          'lat': 41.9747374,\n",
    "          'lon': -87.6920102,\n",
    "          'timestamp': '2010-07-22T16:16:51Z',\n",
    "      'changeset': 5288876},\n",
    " 'node_tags': [{'id': 757860928,\n",
    "                'key': 'amenity',\n",
    "                'value': 'fast_food',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'cuisine',\n",
    "                'value': 'sausage',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'name',\n",
    "                'value': \"Shelly's Tasty Freeze\",\n",
    "                'type': 'regular'}]}\n",
    "\n",
    "### If the element top level tag is \"way\":\n",
    "The dictionary should have the format {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}\n",
    "\n",
    "The \"way\" field should hold a dictionary of the following top level way attributes:\n",
    "- id\n",
    "-  user\n",
    "- uid\n",
    "- version\n",
    "- timestamp\n",
    "- changeset\n",
    "\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"way_tags\" field should again hold a list of dictionaries, following the exact same rules as\n",
    "for \"node_tags\".\n",
    "\n",
    "Additionally, the dictionary should have a field \"way_nodes\". \"way_nodes\" should hold a list of\n",
    "dictionaries, one for each nd child tag.  Each dictionary should have the fields:\n",
    "- id: the top level element (way) id\n",
    "- node_id: the ref attribute value of the nd tag\n",
    "- position: the index starting at 0 of the nd tag i.e. what order the nd tag appears within\n",
    "            the way element\n",
    "\n",
    "The final return value for a \"way\" element should look something like:\n",
    "\n",
    "{'way': {'id': 209809850,\n",
    "         'user': 'chicago-buildings',\n",
    "         'uid': 674454,\n",
    "         'version': '1',\n",
    "         'timestamp': '2013-03-13T15:58:04Z',\n",
    "         'changeset': 15353317},\n",
    " 'way_nodes': [{'id': 209809850, 'node_id': 2199822281, 'position': 0},\n",
    "               {'id': 209809850, 'node_id': 2199822390, 'position': 1},\n",
    "               {'id': 209809850, 'node_id': 2199822392, 'position': 2},\n",
    "               {'id': 209809850, 'node_id': 2199822369, 'position': 3},\n",
    "               {'id': 209809850, 'node_id': 2199822370, 'position': 4},\n",
    "               {'id': 209809850, 'node_id': 2199822284, 'position': 5},\n",
    "               {'id': 209809850, 'node_id': 2199822281, 'position': 6}],\n",
    " 'way_tags': [{'id': 209809850,\n",
    "               'key': 'housenumber',\n",
    "               'type': 'addr',\n",
    "               'value': '1412'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street',\n",
    "               'type': 'addr',\n",
    "               'value': 'West Lexington St.'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:name',\n",
    "               'type': 'addr',\n",
    "               'value': 'Lexington'},\n",
    "              {'id': '209809850',\n",
    "               'key': 'street:prefix',\n",
    "               'type': 'addr',\n",
    "               'value': 'West'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:type',\n",
    "               'type': 'addr',\n",
    "               'value': 'Street'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building',\n",
    "               'type': 'regular',\n",
    "               'value': 'yes'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'levels',\n",
    "               'type': 'building',\n",
    "               'value': '1'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building_id',\n",
    "               'type': 'chicago',\n",
    "               'value': '366409'}]}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the\n",
    "# sql table schema\n",
    "OSM_PATH = 'temple_terrace.osm'\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "    node_attribs = {} \n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        for i in NODE_FIELDS:\n",
    "            node_attribs[i] = element.attrib[i]\n",
    "        for tag in element.iter(\"tag\"):  \n",
    "            problem = PROBLEMCHARS.search(tag.attrib['k'])\n",
    "            if not problem:\n",
    "                node_tag = {} \n",
    "                node_tag['id'] = element.attrib['id'] \n",
    "                node_tag['value'] = tag.attrib['v']  \n",
    "\n",
    "                match = LOWER_COLON.search(tag.attrib['k'])\n",
    "                if not match:\n",
    "                    node_tag['type'] = 'regular'\n",
    "                    node_tag['key'] = tag.attrib['k']\n",
    "                else:\n",
    "                    bef_colon = re.findall('^(.+):', tag.attrib['k'])\n",
    "                    aft_colon = re.findall('^[a-z|_]+:(.+)', tag.attrib['k'])\n",
    "                    node_tag['type'] = bef_colon[0]\n",
    "                    node_tag['key'] = aft_colon[0]\n",
    "                    if node_tag['type'] == \"addr\" and node_tag['key'] == \"street\":\n",
    "                        # update street name\n",
    "                        node_tag['value'] = update_name(tag.attrib['v'], mapping) \n",
    "                    elif node_tag['type'] == \"addr\" and node_tag['key'] == \"postcode\":\n",
    "                        # update post code\n",
    "                        node_tag['value'] = clean_postcode(tag.attrib['v']) \n",
    "\n",
    "\n",
    "            tags.append(node_tag)\n",
    "        \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        for i in WAY_FIELDS:\n",
    "            way_attribs[i] = element.attrib[i]\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            problem = PROBLEMCHARS.search(tag.attrib['k'])\n",
    "            if not problem:\n",
    "                way_tag = {}\n",
    "                way_tag['id'] = element.attrib['id'] \n",
    "                way_tag['value'] = tag.attrib['v']\n",
    "                match = LOWER_COLON.search(tag.attrib['k'])\n",
    "                if not match:\n",
    "                    way_tag['type'] = 'regular'\n",
    "                    way_tag['key'] = tag.attrib['k']\n",
    "                else:\n",
    "                    bef_colon = re.findall('^(.+?):+[a-z]', tag.attrib['k'])\n",
    "                    aft_colon = re.findall('^[a-z|_]+:(.+)', tag.attrib['k'])\n",
    "\n",
    "                    way_tag['type'] = bef_colon[0]\n",
    "                    way_tag['key'] = aft_colon[0]\n",
    "                    if way_tag['type'] == \"addr\" and way_tag['key'] == \"street\":\n",
    "                        way_tag['value'] = update_name(tag.attrib['v'], mapping) \n",
    "                    elif way_tag['type'] == \"addr\" and way_tag['key'] == \"postcode\":\n",
    "                        way_tag['value'] = clean_postcode(tag.attrib['v']) \n",
    "            tags.append(way_tag)\n",
    "        position = 0\n",
    "        for tag in element.iter(\"nd\"):  \n",
    "            nd = {}\n",
    "            nd['id'] = element.attrib['id'] \n",
    "            nd['node_id'] = tag.attrib['ref'] \n",
    "            nd['position'] = position  \n",
    "            position += 1\n",
    "            \n",
    "            way_nodes.append(nd)\n",
    "    \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tampa_cleaned.xml file is 417.46995 MB\n",
      "The tampa.db file is 147.521536 MB\n",
      "The nodes.csv file is 161.004855 MB\n",
      "The nodes_tags.csv file is 161.004855 MB\n",
      "The ways.csv file is 19.066869 MB\n",
      "The ways_tags.csv is 27.623908 MB\n",
      "The ways_nodes.csv is 52.368008 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print('The tampa_cleaned.xml file is {} MB'.format(os.path.getsize('tampa.osm')/1.0e6))\n",
    "print('The tampa.db file is {} MB'.format(os.path.getsize('tampa.db')/1.0e6))\n",
    "print('The nodes.csv file is {} MB'.format(os.path.getsize('nodes.csv')/1.0e6))\n",
    "print('The nodes_tags.csv file is {} MB'.format(os.path.getsize('nodes.csv')/1.0e6))\n",
    "print('The ways.csv file is {} MB'.format(os.path.getsize('ways.csv')/1.0e6))\n",
    "print('The ways_tags.csv is {} MB'.format(os.path.getsize('ways_tags.csv')/1.0e6))\n",
    "print('The ways_nodes.csv is {} MB'.format(os.path.getsize('ways_nodes.csv')/1.0e6)) # Convert from bytes to MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "sqlite_file = \"tampa.db\"\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1048575,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM nodes;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(291596,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM ways;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(893,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Andrew Matheny_import', 404260),\n",
      " (u'ninja_import', 94536),\n",
      " (u'EdHillsman', 91743),\n",
      " (u'woodpeck_fixbot', 59404),\n",
      " (u'coleman', 58410),\n",
      " (u'David Hey', 57929),\n",
      " (u'KalininOV', 57366),\n",
      " (u'grouper', 39270),\n",
      " (u'jharpster', 37479),\n",
      " (u'Jack the Ripper', 32749)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cur.execute(\"SELECT e.user, COUNT(*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e GROUP BY e.user ORDER BY num DESC LIMIT 10;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(28,)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*) FROM nodes_tags WHERE value LIKE '%Starbucks%';\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'hotel', 115),\n",
      " (u'information', 57),\n",
      " (u'motel', 50),\n",
      " (u'attraction', 21),\n",
      " (u'viewpoint', 16),\n",
      " (u'museum', 15),\n",
      " (u'artwork', 12),\n",
      " (u'picnic_site', 12),\n",
      " (u'theme_park', 9),\n",
      " (u'camp_site', 6),\n",
      " (u'zoo', 4),\n",
      " (u'caravan_site', 3),\n",
      " (u'terminal', 2),\n",
      " (u'apartment', 1),\n",
      " (u'aquarium', 1),\n",
      " (u'guest_house', 1),\n",
      " (u'hostel', 1),\n",
      " (u'zoo;attraction', 1)]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "cur.execute (\"SELECT tags.value, COUNT(*) as count FROM (SELECT * FROM nodes_tags UNION ALL \\\n",
    "             SELECT * FROM ways_tags) tags \\\n",
    "             WHERE tags.key LIKE '%tourism'\\\n",
    "             GROUP BY tags.value \\\n",
    "             ORDER BY count DESC;\")\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Tampa', 129),\n",
      " (u'St. Petersburg', 24),\n",
      " (u'Saint Petersburg', 17),\n",
      " (u'Brandon', 14),\n",
      " (u'Clearwater', 5),\n",
      " (u'Oldsmar', 5),\n",
      " (u'Pinellas Park', 4),\n",
      " (u'Riverview', 3),\n",
      " (u'Apollo Beach', 1),\n",
      " (u'Dover', 1),\n",
      " (u'Gibsonton', 1),\n",
      " (u'Temple Terrace', 1),\n",
      " (u'Valrico', 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pprint\n",
    "cur.execute(\"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) \\\n",
    "            FROM nodes_tags WHERE value = 'restaurant') i ON nodes_tags.id = i.id WHERE nodes_tags.key = 'city'\\\n",
    "            GROUP BY nodes_tags.value ORDER BY num DESC;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Starbucks', 15),\n",
      " (u\"Dunkin' Donuts\", 3),\n",
      " (u'Starbucks Coffee', 3),\n",
      " (u'Kaleisia Tea Lounge', 2),\n",
      " (u'Tropical Smoothie Cafe', 2)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute (\"SELECT nodes_tags.value, COUNT(*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) \\\n",
    "             FROM nodes_tags WHERE value='cafe') i ON nodes_tags.id=i.id WHERE nodes_tags.key='name' \\\n",
    "             GROUP BY nodes_tags.value ORDER BY num DESC LIMIT 5;\")\n",
    "\n",
    "pprint.pprint(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
