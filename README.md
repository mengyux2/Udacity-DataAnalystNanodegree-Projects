# Udacity DataAnalyst Nanodegree Projects(2017)

[link to certificate](https://confirm.udacity.com/UUD93YLL)
6 projects associated with Udacity Data Analyst Nanodegree. Skills used for those projects include data operations with numpy and Pandas, visualizations using matplotlib. R programming and its visualization tool ggplot2 were also used in similar tasks. Python were used for parsing json and xml object in some of data wrangling projects. sklearn toolkits were used in machine learning project. Tableau was used for some of interactive data visualization tasks.  

**Full jupyter notebook of each project can be found in each folder.** 


## Individual project description
**Project 0: Analyze Bay Area Bike Share Data** (prep project for the nanodegree, a walkthrough of data analysis using Bay Area Bike Share Data as an example, a warm up for python, numpy, pandas and matplotlib).  

**Project 1: Test a Perceptual Phenomenon.** This project is to use statistical inference to investigate a classic phenomenon from experimental psychology called the Stroop Effect. Basic statistical parameters were calculated based on the given data, a paired t test was used for hypothesis testing.

**Project 2: Investigate Titanic Survival Data.** This project is to use the Python libraries NumPy, pandas, and Matplotlib to investigate Titanic Survival Data and communicate the discoveries using visualization. The goal of this project is to go through the data analysis process and see how everything fits together. Also, a tableau story was build for [interactive visualization](https://public.tableau.com/profile/mengyu.xie#!/vizhome/titanic_workbook_feedback_revised1/Titanicstory). 

**Project 3: Wrangle OpenStreetMap Data.** This project is to first parse data queried from https://www.openstreetmap.org and use data munging techniques, such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity, to clean the OpenStreetMap data for a part of the world(in my case, Tampa, FL). Finally, use SQL as the data schema to store the information. The goal of this project is to practice parsing and gathering data from popular file formats such as .csv, .json, .xml, and .html, processing data from multiple files or very large files that can be cleaned programmatically, and to learn how to store, query, and aggregate data using MongoDB or SQL.  

**Project 4: Exploritory Data Analysis(EDA) of Wine Quality Data with R.** This project is to use R and apply exploratory data analysis techniques to explore relationships in one variable to multiple variables and to explore a selected data set for distributions, outliers, and anomalies.

**Project 5: Identify Fruad from Enron Email.** This project is to build an algorithm to identify Enron Employees who may have committed fraud based on the public Enron financial and email dataset. This project involves data cleaning and feature selection using Python that extracts and identifies useful features that best represent the data, algorithm selection and parameter tuning based on cross validation  with metrics such as precision and recall, F1 score. Finally, an algorithm that performed best on training data was used for fraud detection on testing data.  


